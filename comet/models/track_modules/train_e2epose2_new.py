import os
import numpy as np
import matplotlib.pyplot as plt
import csv
import warnings
warnings.filterwarnings("ignore", r"Parameter '.*' is unused\.")
import pickle
from accelerate import Accelerator, DistributedDataParallelKwargs, GradScalerKwargs
from hydra.utils import instantiate
from omegaconf import OmegaConf, DictConfig
from pytorch3d.implicitron.tools import model_io, vis_utils
from train_util import *
from train_eval_func import train_or_eval_fn

import psutil
import traceback
import gc
import torch
from datetime import datetime
import os

class StatsLogger:
    def __init__(self, exp_dir, metrics=None):
        self.exp_dir = exp_dir
        os.makedirs(self.exp_dir, exist_ok=True)
        self.metrics = metrics if metrics else ["loss", "val_loss", "lr"]
        self.stats = {key: [] for key in self.metrics}
        self.epochs = []

    def update(self, epoch, **kwargs):
        self.epochs.append(epoch)
        for key in self.metrics:
            self.stats[key].append(kwargs.get(key, None))

    def save_csv(self):
        csv_path = os.path.join(self.exp_dir, "train_stats.csv")
        with open(csv_path, "w", newline="") as csvfile:
            writer = csv.writer(csvfile)
            header = ["epoch"] + self.metrics
            writer.writerow(header)
            for i in range(len(self.epochs)):
                row = [self.epochs[i]] + [self.stats[m][i] for m in self.metrics]
                writer.writerow(row)

    def plot_stats(self):
        for metric in self.metrics:
            plt.figure()
            plt.plot(self.epochs, self.stats[metric], marker="o")
            plt.xlabel("Epoch")
            plt.ylabel(metric)
            plt.title(f"{metric} curve")
            plt.grid(True)
            plt.savefig(os.path.join(self.exp_dir, f"{metric}_curve.png"))
            plt.close()


def log_memory_status(step, location, extra_info=None):
    """è®°å½•å†…å­˜çŠ¶æ€"""
    process = psutil.Process()
    current_memory = process.memory_info().rss
    gpu_memory = torch.cuda.memory_allocated()
    gpu_reserved = torch.cuda.memory_reserved()

    print(f"\nğŸ’¾ Memory Status at {location}:")
    print(f"Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"CPU Memory: {current_memory / 1024 ** 3:.2f} GB")
    print(f"GPU Allocated: {gpu_memory / 1024 ** 3:.2f} GB")
    print(f"GPU Reserved: {gpu_reserved / 1024 ** 3:.2f} GB")
    if extra_info:
        print(f"Additional Info: {extra_info}")
    print("-" * 50)

    return current_memory

def train_fn(cfg: DictConfig):
    #######################1. é…ç½®åˆå§‹åŒ–#############################
    OmegaConf.set_struct(cfg, False) # é€šè¿‡ OmegaConf å…³é—­äº†é…ç½®çš„ç»“æ„æ€§æ£€æŸ¥ï¼Œå…è®¸åŠ¨æ€ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„å­—æ®µã€‚

    accelerator = Accelerator(even_batches=False, device_placement=False, mixed_precision=cfg.mixed_precision)
    # ä½¿ç”¨ accelerate åº“åˆå§‹åŒ–ä¸€ä¸ª Accelerator å®ä¾‹ï¼Œä¸»è¦ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦è®­ç»ƒçš„ç®¡ç†ã€‚ even_batches=Falseï¼šè¿™å¯èƒ½è¡¨ç¤ºä¸å¯¹æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡è¿›è¡Œå¹³å‡ mixed_precision=cfg.mixed_precisionï¼šæ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®å†³å®šæ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

    accelerator.print("Model Config:") # æ‰“å°å‡ºæ¨¡å‹çš„é…ç½®ã€‚
    accelerator.print(OmegaConf.to_yaml(cfg)) # ä»¥ YAML æ ¼å¼æ‰“å°æ•´ä¸ªé…ç½®æ–‡ä»¶ã€‚è¿™ä¸ªè¾“å‡ºæœ‰åŠ©äºè°ƒè¯•å’ŒæŸ¥çœ‹è®­ç»ƒæ—¶çš„æ‰€æœ‰é…ç½®

    accelerator.print(accelerator.state)

##########################è®¾å¤‡ä¸è°ƒè¯•æ¨¡å¼########################
    if cfg.debug: # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„ debug å­—æ®µï¼Œå†³å®šæ˜¯å¦è¿›å…¥è°ƒè¯•æ¨¡å¼ã€‚
        accelerator.print("********DEBUG MODE********")
        torch.backends.cudnn.deterministic = True # è®¾ç½® PyTorch ä½¿ç”¨ç¡®å®šæ€§çš„ç®—æ³•ï¼Œä¿è¯æ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´ã€‚å¸¸ç”¨äºè°ƒè¯•å’Œé‡ç°å®éªŒã€‚
        torch.backends.cudnn.benchmark = False # å…³é—­ cudnn ä¸­çš„è‡ªåŠ¨è°ƒä¼˜ï¼Œé€‚ç”¨äºè¾“å…¥å¤§å°ä¸å›ºå®šæˆ–å˜åŠ¨çš„æƒ…å†µã€‚å¦‚æœè¾“å…¥æ•°æ®å¤§å°ä¸ä¸€è‡´ï¼Œè®¾ç½®ä¸º False å¯ä»¥é¿å…æ€§èƒ½æ³¢åŠ¨ã€‚
    else:
        torch.backends.cudnn.benchmark = getattr(cfg.train, "cudnnbenchmark", True)

##############################3. è®¾å®šéšæœºç§å­ ä¿è¯å¯å¤ç°æ€§###############
    set_seed_and_print(cfg.seed) # æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„ seed è®¾ç½®éšæœºç§å­ã€‚è¿™é€šå¸¸æ˜¯ä¸ºäº†ä¿è¯å®éªŒçš„å¯å¤ç°æ€§ã€‚

#############################4. è®­ç»ƒå¯è§†åŒ–####################
    if accelerator.is_main_process: # æ£€æŸ¥å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œåªæœ‰ä¸»è¿›ç¨‹ä¼šæ‰§è¡ŒæŸäº›æ“ä½œï¼Œä¾‹å¦‚æ•°æ®å¯è§†åŒ–ï¼‰ã€‚
        stats_logger = StatsLogger(cfg.exp_dir, metrics=["loss", "val_loss", "lr"])

    ###########################5. æ„å»ºæ•°æ®é›†#############################
    # Building datasets è°ƒç”¨ build_dataset å‡½æ•°ï¼Œæ„å»ºè®­ç»ƒå’Œè¯„ä¼°æ‰€éœ€çš„æ•°æ®é›†å¯¹è±¡å’Œæ•°æ®åŠ è½½å™¨ï¼ˆdataloader æ˜¯è®­ç»ƒé›†çš„æ•°æ®åŠ è½½å™¨ï¼Œeval_dataloader æ˜¯è¯„ä¼°é›†çš„æ•°æ®åŠ è½½å™¨
    dataset, eval_dataset, dataloader, eval_dataloader = build_dataset(cfg) # mix æ··åˆçš„æ–¹å¼

    # to make accelerator happy è®¾ç½®è®­ç»ƒé›†çš„æ•°æ®åŠ è½½å™¨ï¼Œç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡çš„å¤§å°éƒ½æ˜¯å®Œæ•´çš„ã€‚drop_last=True ä¼šä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ã€‚
    dataloader.batch_sampler.drop_last = True
    eval_dataloader.batch_sampler.drop_last = True

#################################6. å®ä¾‹åŒ–æ¨¡å‹############################
    # Instantiate the model æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„ MODEL å­—æ®µï¼Œä½¿ç”¨ Hydra çš„ instantiate å‡½æ•°åŠ¨æ€åˆ›å»ºæ¨¡å‹å®ä¾‹ã€‚_recursive_ å‚æ•°æ§åˆ¶æ˜¯å¦é€’å½’å®ä¾‹åŒ–æ¨¡å‹ä¸­çš„å­ç»„ä»¶ã€‚
    try:
        model = instantiate(cfg.MODEL, _recursive_=False, cfg=cfg)
        model = model.to(accelerator.device)
    except Exception as e:
        raise RuntimeError(f"Failed to instantiate the model with error: {e}")

    num_epochs = cfg.train.epochs # 500 ä»é…ç½®æ–‡ä»¶ä¸­è·å–è®­ç»ƒçš„æ€» epoch æ•°ã€‚

    # Building optimizer ###############7. æ„å»ºä¼˜åŒ–å™¨########################
    optimizer, lr_scheduler = build_optimizer(cfg, model, dataloader) # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°å’Œè®­ç»ƒé›†æ•°æ®æ„å»ºä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰å’Œ
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆlr_schedulerï¼‰ã€‚ä¼˜åŒ–å™¨æ§åˆ¶æ¨¡å‹çš„æƒé‡æ›´æ–°ï¼Œå­¦ä¹ ç‡è°ƒåº¦å™¨æ§åˆ¶å­¦ä¹ ç‡çš„å˜åŒ–ã€‚

    ########################################################################################################################
    if cfg.train.resume_ckpt: # æ£€æŸ¥æ¢å¤æ ‡å¿—ï¼šé¦–å…ˆæ£€æŸ¥ cfg.train.resume_ckpt æ˜¯å¦ä¸º Trueï¼Œè¡¨ç¤ºæ˜¯å¦æ‰‹åŠ¨æ¢å¤æ¨¡å‹çš„çŠ¶æ€ã€‚ä¸æ˜¯ç¬¬ä¸€æ¬¡å°±æ³¨é‡Šæ‰
        # ç¬¬ä¸€æ¬¡æ¢å¤ï¼ˆload_model_weightsï¼‰ï¼šæ¢å¤çš„æ˜¯æ¨¡å‹model(å¦‚å…¶åï¼‰çš„æƒé‡ï¼Œç”¨äºåŠ è½½ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚
        accelerator.print(f"Loading ckpt from {cfg.train.resume_ckpt}") # å¦‚æœä¸º Trueï¼Œæ‰“å°åŠ è½½çš„æ£€æŸ¥ç‚¹è·¯å¾„ã€‚
        model = load_model_weights(model, cfg.train.resume_ckpt, accelerator.device, cfg.relax_load) # è€Œ cfg.relax_load æ˜¯ä¸€ä¸ªæ ‡å¿—ï¼Œè¡¨ç¤ºæ˜¯å¦æ¾å¼›åŠ è½½è¦æ±‚ï¼Œå¯èƒ½å…è®¸åŠ è½½ä¸å®Œå…¨åŒ¹é…çš„æ¨¡å‹æƒé‡ã€‚
        # å¦‚æœä¸º Trueï¼Œé€šè¿‡è°ƒç”¨ load_model_weights å‡½æ•°æ¥åŠ è½½æ¨¡å‹æƒé‡ï¼Œè¿™é‡Œä½¿ç”¨äº† accelerator.device æ¥ç¡®ä¿åŠ è½½åˆ°æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆä¾‹å¦‚ GPU æˆ– CPUï¼‰ã€‚


    ################################################9. Accelerator é¢„å¤„ç†####################################
    # accelerator preparation åŠ é€Ÿå™¨å‡†å¤‡ã€‚ é€šè¿‡ accelerator.prepare() å‡½æ•°å°†æ¨¡å‹ã€æ•°æ®åŠ è½½å™¨ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ä¼ å…¥åŠ é€Ÿå™¨ã€‚è¿™ä¼šç¡®ä¿å®ƒä»¬èƒ½å¤Ÿåœ¨å¤šè®¾å¤‡æˆ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­æ­£ç¡®è¿è¡Œã€‚
    model, dataloader, optimizer, lr_scheduler = accelerator.prepare(model, dataloader, optimizer, lr_scheduler)

    accelerator.print("length of train dataloader is: ", len(dataloader)) # æ‰“å°è®­ç»ƒæ•°æ®åŠ è½½å™¨çš„é•¿åº¦ã€‚
    accelerator.print("length of eval dataloader is: ", len(eval_dataloader))

    accelerator.print(f"dataloader has {dataloader.num_workers} num_workers") # æ‰“å°æ•°æ®åŠ è½½å™¨çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚

############################################10. è®­ç»ƒçŠ¶æ€åˆå§‹åŒ–###########################
    start_epoch = 0
    stats = VizStats(TO_PLOT_METRICS) # åˆ›å»ºä¸€ä¸ª VizStats å®ä¾‹ï¼ŒTO_PLOT_METRICS æ˜¯ä¸€ä¸ªå®šä¹‰è¦ç»˜åˆ¶çš„æŒ‡æ ‡çš„å¸¸é‡ã€‚åŒ…å«å¾ˆå¤šè¦ç»˜åˆ¶çš„å†…å®¹ï¼Œç»Ÿè®¡é‡lossç­‰

    if cfg.train.auto_resume: # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡ªåŠ¨æ¢å¤ã€‚å¦‚æœä¸º Trueï¼Œåˆ™è¡¨ç¤ºè®­ç»ƒå°†è‡ªåŠ¨ä»æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤ã€‚
        # ç¬¬äºŒæ¬¡æ¢å¤ï¼ˆaccelerator.load_stateï¼‰ï¼šæ¢å¤çš„æ˜¯æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„æƒé‡ã€ä¼˜åŒ–å™¨çš„çŠ¶æ€ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ç­‰ã€‚
        # if cfg.debug:
        #     import pdb;pdb.set_trace()

        last_checkpoint = find_last_checkpoint(cfg.exp_dir) # é€šè¿‡ find_last_checkpoint å‡½æ•°æŸ¥æ‰¾ä¸Šä¸€æ¬¡è®­ç»ƒçš„æ£€æŸ¥ç‚¹ï¼Œ
        # cfg.exp_dir æ˜¯ä¿å­˜å®éªŒçš„ç›®å½•åªæ˜¯ä¸€ä¸ªç›®å½•ä¸‹é¢åˆå¾ˆå¤šæ–‡ä»¶

        try: # å°è¯•ä»¥ä¸‹ä»£ç å—ï¼Œå¦‚æœå‡ºé”™åˆ™è¿›å…¥ except éƒ¨åˆ†ã€‚
            resume_epoch = int(os.path.basename(last_checkpoint)[5:]) # ä»æ£€æŸ¥ç‚¹è·¯å¾„çš„æ–‡ä»¶åä¸­æå– epoch ä¿¡æ¯
            # ï¼ˆå‡è®¾æ–‡ä»¶åçš„å‰ 5 ä¸ªå­—ç¬¦åè·Ÿç€æ•°å­—è¡¨ç¤º epochï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ–‡ä»¶åä¸º ckpt_5ï¼Œåˆ™æå– 5 ä½œä¸ºæ¢å¤çš„ epochã€‚
        except:
            resume_epoch = -1

        #################################12. å¯åŠ¨è®­ç»ƒ#############################
        if last_checkpoint is not None and resume_epoch > 0: # å¦‚æœæ‰¾åˆ°äº†æœ‰æ•ˆçš„æ£€æŸ¥ç‚¹ï¼Œå¹¶ä¸”æ¢å¤çš„ epoch å¤§äº 0ï¼Œè¿›è¡Œæ¢å¤æ“ä½œã€‚
            accelerator.print(f"Loading ckpt from {last_checkpoint}")

            accelerator.load_state(last_checkpoint) # åŠ è½½æ£€æŸ¥ç‚¹çš„çŠ¶æ€ã€‚

            try:
                loaded_tdict = pickle.load(open(os.path.join(last_checkpoint, "tdict.pkl"), "rb")) # ä»æ£€æŸ¥ç‚¹åŠ è½½è®­ç»ƒå­—å…¸ï¼ˆåŒ…å« epoch ç­‰ä¿¡æ¯ï¼‰ã€‚
                # åŠ è½½æ£€æŸ¥ç‚¹ç›®å½•ä¸­çš„ tdict.pkl æ–‡ä»¶ï¼Œå®ƒåŒ…å«äº†è®­ç»ƒçš„ç›¸å…³ä¿¡æ¯ï¼Œæ¯”å¦‚ä¸Šæ¬¡è®­ç»ƒçš„ epochã€‚
                start_epoch = loaded_tdict["epoch"]+1  # + 1 # ä»åŠ è½½çš„å­—å…¸ä¸­æå– epochï¼Œå¹¶å°† start_epoch è®¾ç½®ä¸ºä¸Šæ¬¡è®­ç»ƒçš„ epochï¼ˆå‡ 1 æ˜¯ä¸ºäº†ä»ä¸‹ä¸€ä¸ª epoch å¼€å§‹
            except:
                start_epoch = resume_epoch+1  # + 1

            try: # å°è¯•åŠ è½½å­˜å‚¨è®­ç»ƒç»Ÿè®¡ä¿¡æ¯çš„æ–‡ä»¶ train_stats.jgzã€‚
                stats = stats.load(os.path.join(last_checkpoint, "train_stats.jgz"))
            except:
                stats.hard_reset(epoch=start_epoch) # å¦‚æœåŠ è½½ç»Ÿè®¡æ•°æ®å¤±è´¥ï¼Œé‡ç½®ç»Ÿè®¡æ•°æ®ã€‚
                accelerator.print(f"No stats to load from {last_checkpoint}")
        else:
            accelerator.print(f"Starting from scratch") # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œåˆ™ä»å¤´å¼€å§‹è®­ç»ƒã€‚

########################################1. è®­ç»ƒä¸»å¾ªç¯#####################################
    # train_or_eval_fn(
    #     model, dataloader, cfg, optimizer, stats,
    #     accelerator, lr_scheduler, training=True, epoch=start_epoch
    # )

    for epoch in range(start_epoch, num_epochs): # è¿™è¡Œä»£ç å¯åŠ¨äº†ä¸€ä¸ª epoch å¾ªç¯ï¼Œä» start_epoch å¼€å§‹ï¼Œä¸€ç›´åˆ° num_epochs
        stats.new_epoch() # ä¸ºå½“å‰çš„ epoch åˆ›å»ºä¸€ä¸ªæ–°çš„ç»Ÿè®¡è®°å½•ã€‚VizStats ç±»è´Ÿè´£ç»Ÿè®¡å’Œå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡ï¼ˆå¦‚æŸå¤±ã€å‡†ç¡®ç‡ç­‰ï¼‰ï¼Œæ¯ä¸ª epoch å¼€å§‹æ—¶æ›´æ–°ä¸€æ¬¡
        set_seed_and_print(cfg.seed + epoch * 1000) # å®ƒæ ¹æ®ç»™å®šçš„ cfg.seed å’Œå½“å‰ epoch æ¥è®¾ç½®éšæœºç§å­ã€‚epoch * 1000 ä½¿å¾—æ¯ä¸ª epoch çš„ç§å­å€¼ä¸åŒï¼Œ
        # ä»¥ç¡®ä¿æ¯æ¬¡è®­ç»ƒæ—¶çš„éšæœºæ€§ï¼ˆä¾‹å¦‚åˆå§‹åŒ–å’Œæ•°æ®åŠ è½½çš„éšæœºæ€§ï¼‰æ˜¯å”¯ä¸€çš„ã€‚ æ‰“å°å½“å‰ä½¿ç”¨çš„éšæœºç§å­ï¼Œä»¥ä¾¿è°ƒè¯•å’Œå¤ç°ã€‚

           ################################æ¯éš” ckpt_interval ä¸ª epoch è¿›è¡Œä¸€æ¬¡æ£€æŸ¥ç‚¹ä¿å­˜ï¼š#################
        if (epoch != 0) and epoch % cfg.train.ckpt_interval == 0: # åªæœ‰å½“ epoch ä¸æ˜¯ç¬¬ä¸€ä¸ª epoch ä¸”å½“å‰ epoch æ˜¯ cfg.train.ckpt_interval çš„å€æ•°æ—¶ï¼Œæ‰ä¼šæ‰§è¡Œä¿å­˜æ£€æŸ¥ç‚¹æ“ä½œã€‚
            ckpt_path = os.path.join(cfg.exp_dir, f"ckpt_{epoch:06}") #æ ¹æ®å½“å‰çš„ epoch åˆ›å»ºä¸€ä¸ªæ£€æŸ¥ç‚¹è·¯å¾„ ckpt_pathã€‚è·¯å¾„ä¼šä¿å­˜åˆ° cfg.exp_dir ç›®å½•ä¸‹ï¼Œæ–‡ä»¶åæ ¼å¼ä¸º ckpt_000001ï¼ˆå¦‚æœæ˜¯ç¬¬ 1 ä¸ª epochï¼‰
            accelerator.print(f"----------Saving the ckpt at epoch {epoch} to {ckpt_path}----------") # æ‰“å°ä¸€æ¡æ¶ˆæ¯ï¼Œè¯´æ˜å½“å‰æ­£åœ¨ä¿å­˜çš„æ£€æŸ¥ç‚¹æ˜¯é’ˆå¯¹å“ªä¸ª epoch

            if accelerator.is_main_process: # accelerator.is_main_process ç¡®ä¿åœ¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä»…ä¸»è¿›ç¨‹ï¼ˆé€šå¸¸æ˜¯ GPU 0ï¼‰è¿›è¡Œä¿å­˜æ“ä½œã€‚è¿™å¯ä»¥é¿å…å¤šæ¬¡ä¿å­˜ç›¸åŒçš„æ£€æŸ¥ç‚¹ã€‚
                accelerator.save_state(output_dir=ckpt_path, safe_serialization=False) # å­˜å½“å‰çš„è®­ç»ƒçŠ¶æ€ï¼ˆåŒ…æ‹¬æ¨¡å‹çš„æƒé‡ã€ä¼˜åŒ–å™¨çš„çŠ¶æ€ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ç­‰ï¼‰ã€‚ä¿å­˜çš„ç›®å½•æ˜¯ ckpt_pathï¼Œå³å½“å‰ epoch å¯¹åº”çš„è·¯å¾„ã€‚
                pickle.dump({"epoch": epoch, "cfg": cfg}, open(os.path.join(ckpt_path, "tdict.pkl"), "wb"))
                # å°†å½“å‰çš„ epoch å’Œé…ç½® cfg ä¿å­˜åˆ° tdict.pkl æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åœ¨æ¢å¤è®­ç»ƒæ—¶èƒ½å¤Ÿè¯»å–åˆ°è¿™äº›ä¿¡æ¯ã€‚pickle ç”¨äºåºåˆ—åŒ– Python å¯¹è±¡
                stats.save(os.path.join(ckpt_path, "train_stats.jgz")) # å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¾‹å¦‚æŸå¤±ã€ç²¾åº¦ç­‰ï¼‰ä¿å­˜åˆ° train_stats.jgz æ–‡ä»¶ä¸­ã€‚

        # Testing ################6. è¯„ä¼° / æµ‹è¯•è°ƒåº¦############################
        if (epoch != 0) and (epoch % cfg.train.eval_interval == 0): #5
            accelerator.print(f"----------Start to eval at epoch {epoch}----------")
            train_or_eval_fn(
                model, eval_dataloader, cfg, optimizer, stats, accelerator, lr_scheduler, training=False, epoch=epoch
            )  # viz=viz)
        else:
            accelerator.print(f"----------Skip the test/eval at epoch {epoch}----------")

        # Training############################ 7. è®­ç»ƒ ##################################
        accelerator.print(f"----------Start to train at epoch {epoch}----------")

        torch.autograd.set_detect_anomaly(True)  # <=== åŠ åœ¨è¿™é‡Œï¼Œå¯ç”¨å¼‚å¸¸æ£€æµ‹

        train_or_eval_fn(
            model, dataloader, cfg, optimizer, stats,
            accelerator, lr_scheduler, training=True, epoch=epoch
        )

        accelerator.print(f"----------Finish the train at epoch {epoch}----------")

        ######################################8. è®­ç»ƒä¿¡æ¯è®°å½•################################
        if accelerator.is_main_process: # åªæœ‰ä¸»è¿›ç¨‹ï¼ˆé€šå¸¸æ˜¯ GPU 0ï¼‰ä¼šæ‰§è¡Œä¸‹é¢çš„æ“ä½œï¼Œé¿å…å¤šä¸ªè¿›ç¨‹é‡å¤æ“ä½œã€‚
            lr = lr_scheduler.get_last_lr()[0] # è·å–å½“å‰çš„å­¦ä¹ ç‡ã€‚lr_scheduler.get_last_lr() è¿”å›ä¸€ä¸ªåŒ…å«å¤šä¸ªå­¦ä¹ ç‡çš„åˆ—è¡¨ï¼ˆé€‚ç”¨äºå¤šå­¦ä¹ ç‡ç­–ç•¥ï¼‰ï¼Œ[0] æ˜¯æå–ç¬¬ä¸€ä¸ªå­¦ä¹ ç‡å€¼
            accelerator.print(f"----------LR is {lr}----------")
            accelerator.print(f"----------Saving stats to {cfg.exp_name}----------") # æ‰“å°å½“å‰ä¿å­˜è®­ç»ƒç»Ÿè®¡ä¿¡æ¯çš„è·¯å¾„ï¼ˆä½¿ç”¨ cfg.exp_name ä½œä¸ºç›®å½•å
            stats.update({"lr": lr}, stat_set="train") # æ›´æ–°è®­ç»ƒç»Ÿè®¡æ•°æ®ï¼Œæ·»åŠ å½“å‰å­¦ä¹ ç‡ lr
            stats.plot_stats(viz=viz, visdom_env=cfg.exp_name) # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¹¶å°†å…¶å‘é€åˆ°å¯è§†åŒ–å·¥å…·ï¼ˆå¦‚ Visdomï¼‰ã€‚cfg.exp_name ç”¨ä½œ Visdom ç¯å¢ƒçš„åç§°ã€‚
            accelerator.print(f"----------Done----------")
            # viz.save([cfg.exp_name])

        # break

 ####################################9. æœ€ç»ˆä¿å­˜æ£€æŸ¥ç‚¹##########################
    accelerator.save_state(output_dir=os.path.join(cfg.exp_dir, f"ckpt_{epoch:06}"), safe_serialization=False) # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ä¿å­˜å½“å‰çš„è®­ç»ƒçŠ¶æ€ï¼ˆåŒ…æ‹¬æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ç­‰ï¼‰ã€‚
    # ä¿å­˜çš„è·¯å¾„æ˜¯ cfg.exp_dir ç›®å½•ä¸‹ï¼Œä»¥ ckpt_{epoch:06} å‘½å {epoch:06} è¡¨ç¤ºï¼š    # epochï¼šè¦æ ¼å¼åŒ–çš„å˜é‡ã€‚    # :06ï¼šæ ¼å¼è¯´æ˜ï¼š    # 0ï¼šä½¿ç”¨ 0 è¿›è¡Œå¡«å……ï¼ˆè¡¥å…¨ï¼‰ã€‚    # 6ï¼šæ€»å®½åº¦ä¸º 6 ä½ã€‚
    return True

if __name__ == '__main__':
    cfg = OmegaConf.load('train.yaml')
    train_fn(cfg)
